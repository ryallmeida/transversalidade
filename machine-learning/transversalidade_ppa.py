# -*- coding: utf-8 -*-
"""transversalidade_ppa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oO1aJ45qRmyjb2w7mvSIYHv2_3UzNXmJ

## Nota Técnica: Avaliação Modelo de Classificação com SVM em Minning Text
O primeiro código apresentado realiza um pipeline clássico de classificação de texto utilizando a combinação entre vetorização por TF-IDF e um classificador LinearSVC. Essa abordagem é bastante comum na literatura de aprendizado de máquina aplicada a texto, por sua simplicidade e eficiência. Contudo, embora o código forneça resultados aparentemente excelentes, com uma acurácia geral de 92%, há limitações importantes que precisam ser consideradas para garantir a real robustez, interpretabilidade e confiabilidade do modelo.

1. Problema do desequilíbrio de classes
Um dos principais problemas do primeiro modelo está no desequilíbrio das classes. Conforme os dados apresentados, a classe "Neutral" representa a esmagadora maioria das amostras (mais de 75%), enquanto a classe "Positive" possui apenas 235 exemplos no conjunto de teste. Isso impacta fortemente a avaliação dos resultados: mesmo que o modelo erre todas as amostras minoritárias, ele ainda poderá obter uma acurácia elevada apenas acertando a maioria. O modelo, portanto, se beneficia de um viés estatístico estrutural e não necessariamente de sua capacidade de generalização ou aprendizagem real. Isso fica evidente quando observamos o recall da classe "Positive", que foi de apenas 54%, revelando que quase metade dos exemplos dessa classe passaram despercebidos.

2. Ausência de balanceamento e calibração
O LinearSVC por padrão não leva em conta o desbalanceamento de classes, o que tende a prejudicar ainda mais a detecção de classes minoritárias. O uso do parâmetro class_weight='balanced' força o modelo a dar maior peso às classes sub-representadas, promovendo decisões mais justas no processo de classificação. Além disso, o LinearSVC não retorna probabilidades diretamente — sua saída são scores de decisão, que não são calibrados para refletir incerteza. Isso limita a aplicação de métricas probabilísticas, como curvas ROC e AUC, e prejudica interpretações baseadas em limiares flexíveis de decisão. Por isso, utilizou-se CalibratedClassifierCV, que aplica uma regressão logística (sigmoide) sobre os scores para fornecer probabilidades calibradas por validação cruzada, tornando as saídas mais interpretáveis e confiáveis.

3. Limitações da divisão treino/teste única
Outro ponto frágil do primeiro script é a utilização de apenas uma divisão entre treino e teste. Essa abordagem é sensível ao acaso: um modelo pode ter bom desempenho simplesmente porque “deu sorte” na divisão dos dados. Para resolver isso, a versão aprimorada utiliza validação cruzada estratificada (StratifiedKFold), que distribui as classes proporcionalmente em múltiplas partições e calcula os resultados médios entre elas. Isso reduz a variabilidade dos resultados e oferece uma medida mais realista da performance do modelo em novos dados.

4. Importância de métricas complementares
Por fim, embora o classification_report já forneça métricas relevantes como precisão, recall e F1-score, é essencial visualizá-las no contexto de uma matriz de confusão e das curvas ROC, especialmente quando se deseja compreender o comportamento do modelo para cada classe. A nova versão do código adiciona essas visualizações, permitindo identificar claramente onde ocorrem os maiores erros, quais classes são confundidas entre si e qual é a capacidade do modelo de discriminar corretamente cada categoria.

## Conclusão
Portanto, embora o primeiro código seja funcional e produza bons resultados aparentes, ele apresenta limitações estruturais que podem comprometer a validade externa do modelo. A versão aprimorada corrige essas fragilidades por meio de técnicas fundamentais em ciência de dados: balanceamento de classes, calibração de probabilidades, validação cruzada estratificada e avaliação multidimensional do desempenho. Esses procedimentos não apenas aumentam a confiança nos resultados, mas também tornam o modelo mais justo, transparente e generalizável para diferentes conjuntos de dados. Em projetos de classificação textual com impacto prático — como na análise de políticas públicas, discursos ou opinião —, essas boas práticas são não apenas recomendadas, mas indispensáveis.

## **MODELAGEM COM LINEAR SVC**

## CÓDIGO CALIBRADO
"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_preprocessado_ppa.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['Texto'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf,
                                                    labels_svm,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc,
                                        method='sigmoid',
                                        cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC - One-vs-Rest com LinearSVC (Calibrado)')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Gera as previsões do modelo treinado
y_pred = clf_svc.predict(X_test)

# Gera a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=np.unique(labels_svm))

# Plota a matriz de confusão
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Matriz de Confusão - OneVsRest com LinearSVC Calibrado")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""## **MODELAGEM COM NAIVE BAYES **"""

import pandas as pd
import numpy as np
import psutil
import os
import time

# --- Função auxiliar para mostrar uso de memória ---
def mostrar_uso_memoria():
    processo = psutil.Process(os.getpid())
    mem = processo.memory_info().rss / (1024 ** 2)  # em MB
    print(f"[INFO] Uso atual de memória RAM: {mem:.2f} MB")

print("[ETAPA 1] Lendo o corpus...")
df_corpus = pd.read_csv("/content/corpus_preprocessado_ppa.csv")
mostrar_uso_memoria()

# Verifica colunas
print("[INFO] Colunas do corpus:", df_corpus.columns.tolist())

print("[ETAPA 2] Removendo entradas com dados faltantes...")
df_corpus = df_corpus.dropna(subset=["Texto", "label_final"])
mostrar_uso_memoria()

# Separação de variáveis
textos = df_corpus["Texto"].values
labels = df_corpus["label_final"].values
print(f"[INFO] Total de amostras após limpeza: {len(textos)}")

# Vetorização com CountVectorizer
print("[ETAPA 3] Vetorizando os textos com CountVectorizer...")
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(textos)
mostrar_uso_memoria()

# Cálculo da esparsidade
total_elementos = X.shape[0] * X.shape[1]
elementos_nao_zero = X.nnz
esparcidade = 1.0 - (elementos_nao_zero / total_elementos)
print(f"[INFO] Esparsidade da matriz: {esparcidade:.4f} (valores próximos de 1 indicam muitos zeros)")

# Divisão treino/teste
from sklearn.model_selection import train_test_split
print("[ETAPA 4] Separando dados de treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42, stratify=labels)
mostrar_uso_memoria()

# Treinamento do modelo
from sklearn.naive_bayes import MultinomialNB
print("[ETAPA 5] Treinando o classificador Multinomial Naive Bayes...")
modelo_nb = MultinomialNB()
modelo_nb.fit(X_train, y_train)

# Avaliação
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
print("[ETAPA 6] Avaliando o modelo...")
y_pred = modelo_nb.predict(X_test)
print("\n[RESULTADO] Relatório de Classificação:")
print(classification_report(y_test, y_pred, target_names=["Positive", "Neutral", "Negative"]))

# Matriz de Confusão
print("[ETAPA 7] Gerando matriz de confusão...")
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Positive", "Neutral", "Negative"])
disp.plot(cmap="Blues")
mostrar_uso_memoria()

# Curvas ROC
print("[ETAPA 8] Calculando curva ROC...")
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle

# Binariza as classes
classes_unicas = np.unique(labels)
y_test_bin = label_binarize(y_test, classes=classes_unicas)
y_prob = modelo_nb.predict_proba(X_test)

plt.figure(figsize=(8, 6))
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])

for i, color in zip(range(len(classes_unicas)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2, label=f'Classe {classes_unicas[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.title('Curva ROC - MultinomialNB com CountVectorizer')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

"""## CODIGOS TESTES"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from itertools import cycle
import seaborn as sns

# === 1. Leitura e limpeza ===
df = pd.read_csv("/content/corpus_preprocessado_ppa.csv").dropna()
textos = df['Texto'].values
y = df['label_final'].values  # Certifique-se de que estão codificados como -1, 0, 1

# === 2. Vetorização TF-IDF ===
tfidf = TfidfVectorizer()
X = tfidf.fit_transform(textos)

# === 3. Preparação do modelo base ===
svc_base = LinearSVC(class_weight='balanced', max_iter=10000)
svc_calibrated = CalibratedClassifierCV(svc_base, method='sigmoid', cv=3)

# === 4. Validação cruzada estratificada ===
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
y_pred = cross_val_predict(svc_calibrated, X, y, cv=skf)
y_prob = cross_val_predict(svc_calibrated, X, y, cv=skf, method='predict_proba')

# === 5. Classification report ===
print("=== CLASSIFICATION REPORT (Macro e por classe) ===")
print(classification_report(y, y_pred, target_names=["Positive", "Neutral", "Negative"]))

# === 6. Matriz de confusão ===
conf_mat = confusion_matrix(y, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap="Blues",
            xticklabels=["Positive", "Neutral", "Negative"],
            yticklabels=["Positive", "Neutral", "Negative"])
plt.title("Matriz de Confusão")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()

# === 7. Curvas ROC (requer binarizar labels) ===
# Ajuste se necessário para sua codificação exata
class_names = ["Positive", "Neutral", "Negative"]
y_bin = label_binarize(y, classes=[-1, 0, 1])  # ajuste aqui se suas classes forem diferentes
n_classes = y_bin.shape[1]

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# === 8. Plot ROC ===
plt.figure(figsize=(8, 6))
colors = cycle(['darkorange', 'green', 'red'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {class_names[i]} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curvas ROC por classe')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""Importando bibliotecas necessárias para a manipulação dos dados, lendo o corpus já rotulado, anteriormente via dicionário no R

A função `preprocessamento`, escrita em Python, tem como objetivo principal limpar e preparar textos brutos para tarefas de Processamento de Linguagem Natural (PLN). Esse tipo de pré-processamento é essencial para que algoritmos de aprendizado de máquina ou outras análises computacionais possam lidar melhor com a linguagem humana, que é complexa, ambígua e carregada de elementos que, muitas vezes, não contribuem diretamente para a interpretação semântica.

A função começa recebendo como entrada uma lista de textos. Logo na primeira linha, ela transforma todos os elementos dessa lista em strings, utilizando a função `map(str, textos)`. Isso é uma medida preventiva para evitar erros caso algum item da lista não esteja no formato de texto — como valores nulos (`None`), números inteiros ou flutuantes. Todos esses casos são convertidos para texto bruto, assegurando uniformidade na estrutura de entrada.

Em seguida, utiliza-se a função `nlp.pipe(textos)` da biblioteca spaCy para processar os textos em lote, o que é mais eficiente do que processá-los um por um. Cada elemento retornado por essa função é um objeto do tipo `Doc`, que contém todas as análises linguísticas feitas pelo modelo de linguagem carregado — como a divisão do texto em palavras (tokenização), a identificação do tipo de cada palavra (part-of-speech tagging), e a forma básica de cada palavra (lematização).

Para armazenar os resultados do pré-processamento, a função cria uma lista vazia chamada `textos_preprocessados`. Em seguida, percorre cada um dos documentos linguísticos produzidos pelo spaCy. Dentro desse laço, é feita a principal transformação do texto. Cada documento é decomposto em tokens (as menores unidades linguísticas, geralmente palavras), e sobre esses tokens são aplicados três filtros simultaneamente: primeiro, a lematização, que extrai a forma canônica da palavra — por exemplo, “andando”, “andei” e “andaremos” são reduzidos a “andar”; segundo, a remoção das stop words, que são palavras funcionais da língua, como artigos, preposições e pronomes (“o”, “a”, “de”, “sua”, “que”), que normalmente são descartadas por não carregarem conteúdo semântico relevante; e, por fim, a filtragem para manter apenas os tokens compostos por letras, eliminando números, pontuação e símbolos especiais.

Os tokens resultantes, já lematizados e limpos, são então recombinados em uma única string, unindo as palavras com espaços entre elas. Essa nova versão limpa do texto é adicionada à lista `textos_preprocessados`. Por fim, a função retorna essa lista convertida em um array do tipo NumPy, o que facilita etapas posteriores da análise, como vetorização, clustering, ou treinamento de modelos de classificação.

Em resumo, essa função realiza uma série de etapas fundamentais na preparação de textos: normalização dos dados de entrada, lematização das palavras, remoção de elementos irrelevantes e reconstrução dos textos em uma forma mais enxuta e sem ruído. Trata-se de uma função simples, mas poderosa, que prepara os dados de forma eficiente e compatível com as demandas da análise textual automatizada.

## ABAIXO: CÓDIGO NÃO CALIBRADO
"""

import pandas as pd
import numpy as np
df_corpus_ppa = pd.read_csv("/content/dic2_corpus_ppa.csv")
print(df_corpus_ppa)
# ELIMINANDO NaN DO CORPUS
df_corpus_sem_na = df_corpus_ppa.dropna()
# LISTA DE LABELS SEM NaNs
label_final = list(df_corpus_sem_na['label_final'].values)
label_final
# LISTA DE TEXTOS SEM NAs
textos = list(df_corpus_sem_na['paragrafo'].values)
print(textos)

#limpeza de textos
#lematização (despersonaliza o sujeito)
#stop words (palavras como "sua", "uma", "o", "a"....)
def preprocessamento(textos):
  #tratando qq um que não seja string
  textos = list(map(str,textos))
  #criação de objeto para cada texto
  docs = list(nlp.pipe(textos))
  #aplicando tokenização, remoção de stop words e part-of-speech tagging
  textos_preprocessados = []
  for doc in docs:
    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
    textos_preprocessados.append(' '.join(tokens))
#retorna os resultados do preprocessamento
  return np.array(textos_preprocessados)
  import spacy #carregando bibliotecas e funções de limpeza dos textos
get_ipython().system('python -m spacy download pt_core_news_lg')
nlp = spacy.load("pt_core_news_lg")
texto_corpus_preprocessados = preprocessamento(textos)
print(texto_corpus_preprocessados)
df_corpus_preprocessado = pd.DataFrame(list(zip(texto_corpus_preprocessados,df_corpus_sem_na['label_final'])),
                                        columns = ['Texto','label_final'])
print(df_corpus_preprocessado)
df_corpus_preprocessado.to_csv(r"/content/corpus_preprocessado_ppa.csv")

# ABAIXO CODIGO NÃO CALIBRADO
# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_preprocessado_ppa.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['Texto'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

"""Abaixo segue a modelagem mais precisa ate o momento

## APENDICE
"""

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf,
                                                    labels_svm,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc,
                                        method='sigmoid',
                                        cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC - One-vs-Rest com LinearSVC (Calibrado)')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Leitura do corpus
df = pd.read_csv("/content/corpus_preprocessado_ppa.csv")
df = df.dropna()

# Verificando distribuição das classes
print("\nDistribuição de classes:")
print(df['label_final'].value_counts(normalize=True))
print("\nTotal por classe:", df['label_final'].value_counts())

# Verificando se há apenas três classes
print("\nClasses únicas encontradas:", df['label_final'].unique())

# Extração dos textos e rótulos
textos = df['Texto'].values
labels = df['label_final'].values

# Vetorização com TF-IDF
tfidf = TfidfVectorizer()
X = tfidf.fit_transform(textos)

# Separação treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=0, stratify=labels)

# Treinamento do modelo
clf = LinearSVC(class_weight="balanced", random_state=0)
clf.fit(X_train, y_train)

# Predições
y_pred = clf.predict(X_test)

# Avaliação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

# Matriz de confusão visual
cm = confusion_matrix(y_test, y_pred, labels=np.unique(labels))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=np.unique(labels), yticklabels=np.unique(labels))
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title("Matriz de Confusão")
plt.show()

# Verificando termos mais importantes por classe
try:
    coef = clf.coef_
    for i, classe in enumerate(clf.classes_):
        print(f"\nTop termos para a classe {classe}:")
        top_n = np.argsort(coef[i])[-10:]  # top 10 positivos
        termos = np.array(tfidf.get_feature_names_out())[top_n]
        print(termos)
except Exception as e:
    print("\nErro ao tentar extrair os coeficientes dos termos:", str(e))

# Passo 4: Plotar a matriz de confusão
from sklearn.metrics import confusion_matrix # import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
# Calculate the confusion matrix from the predictions and true labels
cm = confusion_matrix(y_test, predict_cv)

target_names=["Positivo","Neutro","Negativo"]
def plot_confusion_matrix(cm, classes, title='Matriz de Confusão', cmap=plt.cm.Blues):
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.xlabel('Predito')
    plt.ylabel('Real')
    plt.show()

# Exibir o gráfico
plot_confusion_matrix(cm, classes=target_names, title='Matriz de Confusão Naive Bayes com CV')

labels_prob_cv = clf_cv.predict_proba(X_cv_test)
labels_prob_cv

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

def plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC", figsize=(8,6)):
    """
    Plota a Curva ROC para múltiplas classes.

    Parâmetros:
    - y_test: Array com os rótulos verdadeiros.
    - labels_prob_cv: Array com as probabilidades previstas para cada classe.
    - title: Título do gráfico.
    - figsize: Tamanho da figura.
    """
    plt.figure(figsize=figsize)

    # Obter o número de classes
    num_classes = labels_prob_cv.shape[1]

    # Binarize y_test for ROC curve calculation
    from sklearn.preprocessing import label_binarize
    y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))

    for i in range(num_classes):
        # Calculate the ROC curve
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], labels_prob_cv[:, i])
        roc_auc = auc(fpr, tpr)

        # Plot the ROC curve
        plt.plot(fpr, tpr, lw=2, label=f'Classe {np.unique(y_test)[i]} (AUC = {roc_auc:.2f})')

    # Add the diagonal line (randomness line)
    plt.plot([0, 1], [0, 1], 'k--', lw=2)

    # Add title and labels
    plt.title(title)
    plt.xlabel('Taxa de Falsos Positivos')
    plt.ylabel('Taxa de Verdadeiros Positivos')
    plt.legend(loc='lower right')
    plt.grid(True)

    # Show the plot
    plt.show()

# Calculate predicted probabilities
labels_prob_cv = clf_cv.predict_proba(X_cv_test)

# Plot the ROC curves
plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC Naive Bayes com CV", figsize=(8,6))

#A TITULO DE CURIOSIDADE ÉSSE GRAFICO ESTA ERRADO, POIS NÃO ESTA CALIBRADO, VISTO QUE
#O Linear SVC é naturalmente usado para prever classes binárias

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline

import numpy as np

# Binarizar os rótulos
y_svm_binarized = label_binarize(y_svm_test, classes=[0, 1, 2])  # ou use as labels reais se forem strings

# Treinar modelo com probabilidade habilitada
# OBS: LinearSVC não suporta predict_proba, então usamos SVC
clf_roc = OneVsRestClassifier(SVC(kernel="linear", probability=True))
clf_roc.fit(X_svm_train, y_svm_train)
y_score = clf_roc.predict_proba(X_svm_test)

# Número de classes
n_classes = y_score.shape[1]

# Plot da curva ROC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_svm_binarized[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot
plt.figure(figsize=(8, 6))
colors = ['blue', 'green', 'red']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC Multiclasse (One-vs-Rest)')
plt.legend(loc="lower right")
plt.grid()
plt.show()