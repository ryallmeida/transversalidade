# -*- coding: utf-8 -*-
"""naive_bayes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1284ElvlY77PMQEJSTCZuTtJcH-Y4Z1hK

NAIVES BAYES. ALGORITMO USADO PARA PROCESSAR A CORPORA DO PROJETO INTITULADO: EVIDENCIAS DO USO DE ALGORITMOS DE PROCESSAMENTO DE LINGUAGEM NATURAL E MACHINE LEARNING APLICADOS COMO FERRAMENTA DIAGOSTICA √† TRANSVERSALIDADE EM PERNAMBUCO

## **CLASSE TIPO 1 BALANCEADA NAIVE BAYES**
"""

import pandas as pd
import numpy as np
import psutil
import os
import time

# --- Fun√ß√£o auxiliar para mostrar uso de mem√≥ria ---
def mostrar_uso_memoria():
    processo = psutil.Process(os.getpid())
    mem = processo.memory_info().rss / (1024 ** 2)  # em MB
    print(f"[INFO] Uso atual de mem√≥ria RAM: {mem:.2f} MB")

print("[ETAPA 1] Lendo o corpus...")
df_corpus = pd.read_csv("/content/corpus_balanceado_tp1.csv")
mostrar_uso_memoria()

# Verifica colunas
print("[INFO] Colunas do corpus:", df_corpus.columns.tolist())

print("[ETAPA 2] Removendo entradas com dados faltantes...")
df_corpus = df_corpus.dropna(subset=["texto_limpo", "label_final"])
mostrar_uso_memoria()

# Separa√ß√£o de vari√°veis
textos = df_corpus["texto_limpo"].values
labels = df_corpus["label_final"].values
print(f"[INFO] Total de amostras ap√≥s limpeza: {len(textos)}")

# Vetoriza√ß√£o com CountVectorizer
print("[ETAPA 3] Vetorizando os textos com CountVectorizer...")
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(textos)
mostrar_uso_memoria()

# C√°lculo da esparsidade
total_elementos = X.shape[0] * X.shape[1]
elementos_nao_zero = X.nnz
esparcidade = 1.0 - (elementos_nao_zero / total_elementos)
print(f"[INFO] Esparsidade da matriz: {esparcidade:.4f} (valores pr√≥ximos de 1 indicam muitos zeros)")

# Divis√£o treino/teste
from sklearn.model_selection import train_test_split
print("[ETAPA 4] Separando dados de treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42, stratify=labels)
mostrar_uso_memoria()

# Treinamento do modelo
from sklearn.naive_bayes import MultinomialNB
print("[ETAPA 5] Treinando o classificador Multinomial Naive Bayes...")
modelo_nb = MultinomialNB()
modelo_nb.fit(X_train, y_train)

# Avalia√ß√£o
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
print("[ETAPA 6] Avaliando o modelo...")
y_pred = modelo_nb.predict(X_test)
print("\n[RESULTADO] Relat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred, target_names=["Positive", "Neutral", "Negative"]))

# Matriz de Confus√£o
print("[ETAPA 7] Gerando matriz de confus√£o...")
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Positive", "Neutral", "Negative"])
disp.plot(cmap="Blues")
mostrar_uso_memoria()

# Curvas ROC
print("[ETAPA 8] Calculando curva ROC...")
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle

# Binariza as classes
classes_unicas = np.unique(labels)
y_test_bin = label_binarize(y_test, classes=classes_unicas)
y_prob = modelo_nb.predict_proba(X_test)

plt.figure(figsize=(8, 6))
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])

for i, color in zip(range(len(classes_unicas)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2, label=f'Classe {classes_unicas[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.title('Curva ROC - MultinomialNB com CountVectorizer')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. üîπ Carregamento dos dados
df = pd.read_csv("/content/corpus_balanceado_tp1.csv").dropna()
textos = df["texto_limpo"] # Changed 'texto' to 'paragrafo'
rotulos = df["label_final"]

# 2. üîπ Separa√ß√£o treino-teste
X_train, X_test, y_train, y_test = train_test_split(textos, rotulos, test_size=0.2, stratify=rotulos, random_state=42)


grid_nb = GridSearchCV(pipe_nb, param_grid_nb, cv=5, scoring='f1_macro')
grid_nb.fit(X_train, y_train)

print("[INFO] Melhor alpha para NB:", grid_nb.best_params_)
print("[INFO] Melhor f1_macro (CV):", grid_nb.best_score_)

# 6. üîπ Avalia√ß√£o final dos 3 modelos
for nome, modelo in modelos.items():
    print(f"\nüîç Avaliando modelo: {nome}")
    pipe = Pipeline([
        ('vect', vectorizer),
        ('clf', modelo)
    ])
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)

    print(classification_report(y_test, y_pred))

    # Matriz de confus√£o
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=pipe.classes_, yticklabels=pipe.classes_)
    plt.title(f'Matriz de Confus√£o - {nome}')
    plt.xlabel('Predito')
    plt.ylabel('Real')
    plt.tight_layout()
    plt.show()

    # Valida√ß√£o cruzada
    scores = cross_val_score(pipe, textos, rotulos, cv=5, scoring='f1_macro')
    print(f"[INFO] F1 Macro m√©dio (CV): {scores.mean():.4f}")

"""## **CLASSE TIPO 2 BALANCEADA PELO NAIVE BAYES**"""

import pandas as pd
import numpy as np
import psutil
import os

# ===============================
# FUN√á√ÉO AUXILIAR: USO DE MEM√ìRIA
# ===============================
def mostrar_uso_memoria():
    processo = psutil.Process(os.getpid())
    mem = processo.memory_info().rss / (1024 ** 2)
    print(f"[INFO] Uso atual de mem√≥ria RAM: {mem:.2f} MB")


# ===============================
# ETAPA 1 ‚Äî LEITURA DO CORPUS
# ===============================
print("[ETAPA 1] Lendo o corpus...")
df_corpus = pd.read_csv("/content/corpus_balanceado_tp2.csv")
mostrar_uso_memoria()

print("[INFO] Colunas dispon√≠veis:", df_corpus.columns.tolist())


# ===============================
# ETAPA 2 ‚Äî LIMPEZA
# ===============================
print("[ETAPA 2] Removendo dados faltantes...")
df_corpus = df_corpus.dropna(subset=["texto_limpo", "espectro_tipo2"])
mostrar_uso_memoria()


# ===============================
# ETAPA 3 ‚Äî EXTRA√á√ÉO DE VARI√ÅVEIS
# ===============================
textos = df_corpus["texto_limpo"].values
labels = df_corpus["espectro_tipo2"].values

print(f"[INFO] Total de amostras ap√≥s limpeza: {len(textos)}")


# ===============================
# ETAPA 4 ‚Äî DEFINI√á√ÉO EXPL√çCITA DAS CLASSES
# (CRUCIAL PARA MULTICLASSE ASSIM√âTRICA)
# ===============================
labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]
nomes_classes = [str(l) for l in labels_ordem]


# ===============================
# ETAPA 5 ‚Äî VETORIZA√á√ÉO
# ===============================
from sklearn.feature_extraction.text import CountVectorizer

print("[ETAPA 5] Vetorizando textos (CountVectorizer)...")
vectorizer = CountVectorizer(
    min_df=2,        # reduz ru√≠do
    max_df=0.95      # evita termos dominantes
)

X = vectorizer.fit_transform(textos)
mostrar_uso_memoria()

# Diagn√≥stico de esparsidade
total = X.shape[0] * X.shape[1]
esparcidade = 1 - (X.nnz / total)
print(f"[INFO] Esparsidade da matriz: {esparcidade:.4f}")


# ===============================
# ETAPA 6 ‚Äî TREINO / TESTE
# ===============================
from sklearn.model_selection import train_test_split

print("[ETAPA 6] Separando treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(
    X,
    labels,
    test_size=0.25,
    random_state=42,
    stratify=labels
)
mostrar_uso_memoria()


# ===============================
# ETAPA 7 ‚Äî TREINAMENTO
# ===============================
from sklearn.naive_bayes import MultinomialNB

print("[ETAPA 7] Treinando Multinomial Naive Bayes...")
modelo_nb = MultinomialNB()
modelo_nb.fit(X_train, y_train)


# ===============================
# ETAPA 8 ‚Äî AVALIA√á√ÉO
# ===============================
from sklearn.metrics import classification_report

print("\n[RESULTADO] Relat√≥rio de Classifica√ß√£o:")

print(classification_report(
    y_test,
    modelo_nb.predict(X_test),
    labels=labels_ordem,
    target_names=nomes_classes,
    zero_division=0
))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

print("[ETAPA 9] Matriz de confus√£o...")

cm = confusion_matrix(
    y_test,
    modelo_nb.predict(X_test),
    labels=labels_ordem
)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

disp.plot(
    cmap="Blues",
    xticks_rotation=45
)

plt.title("Matriz de Confus√£o ‚Äî MultinomialNB")
plt.tight_layout()
plt.show()

mostrar_uso_memoria()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from itertools import cycle
import matplotlib.pyplot as plt

print("[ETAPA 10] Curvas ROC Multiclasse...")

# Binariza√ß√£o expl√≠cita
y_test_bin = label_binarize(y_test, classes=labels_ordem)
y_prob = modelo_nb.predict_proba(X_test)

plt.figure(figsize=(8, 6))
colors = cycle(plt.cm.tab10.colors)

for i, color in zip(range(len(labels_ordem)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)

    plt.plot(
        fpr,
        tpr,
        lw=2,
        color=color,
        label=f"Classe {labels_ordem[i]} (AUC={roc_auc:.2f})"
    )

plt.plot([0, 1], [0, 1], "k--", lw=1)
plt.xlabel("Taxa de Falsos Positivos")
plt.ylabel("Taxa de Verdadeiros Positivos")
plt.title("Curvas ROC ‚Äî MultinomialNB (Multiclasse)")
plt.legend(fontsize=8)
plt.grid(True)
plt.tight_layout()
plt.show()

"""## **CLASSE TIPO 3 BALANCEADA**"""



import pandas as pd
import numpy as np
import psutil
import os

# ===============================
# FUN√á√ÉO AUXILIAR: USO DE MEM√ìRIA
# ===============================
def mostrar_uso_memoria():
    processo = psutil.Process(os.getpid())
    mem = processo.memory_info().rss / (1024 ** 2)
    print(f"[INFO] Uso atual de mem√≥ria RAM: {mem:.2f} MB")


# ===============================
# ETAPA 1 ‚Äî LEITURA DO CORPUS
# ===============================
print("[ETAPA 1] Lendo o corpus...")
df_corpus = pd.read_csv("/content/corpus_balanceado_tp3.csv")
mostrar_uso_memoria()

print("[INFO] Colunas dispon√≠veis:", df_corpus.columns.tolist())


# ===============================
# ETAPA 2 ‚Äî LIMPEZA
# ===============================
print("[ETAPA 2] Removendo dados faltantes...")
df_corpus = df_corpus.dropna(subset=["texto_limpo", "espectro_tipo3"])
mostrar_uso_memoria()


# ===============================
# ETAPA 3 ‚Äî EXTRA√á√ÉO DE VARI√ÅVEIS
# ===============================
textos = df_corpus["texto_limpo"].values
labels = df_corpus["espectro_tipo3"].values

print(f"[INFO] Total de amostras ap√≥s limpeza: {len(textos)}")


# ===============================
# ETAPA 4 ‚Äî DEFINI√á√ÉO EXPL√çCITA DAS CLASSES
# (CRUCIAL PARA MULTICLASSE ASSIM√âTRICA)
# ===============================
labels_ordem = [-6, -5, -4, -3, -2, 0, 2, 3, 4, 5, 6]
nomes_classes = [str(l) for l in labels_ordem]


# ===============================
# ETAPA 5 ‚Äî VETORIZA√á√ÉO
# ===============================
from sklearn.feature_extraction.text import CountVectorizer

print("[ETAPA 5] Vetorizando textos (CountVectorizer)...")
vectorizer = CountVectorizer(
    min_df=2,        # reduz ru√≠do
    max_df=0.95      # evita termos dominantes
)

X = vectorizer.fit_transform(textos)
mostrar_uso_memoria()

# Diagn√≥stico de esparsidade
total = X.shape[0] * X.shape[1]
esparcidade = 1 - (X.nnz / total)
print(f"[INFO] Esparsidade da matriz: {esparcidade:.4f}")


# ===============================
# ETAPA 6 ‚Äî TREINO / TESTE
# ===============================
from sklearn.model_selection import train_test_split

print("[ETAPA 6] Separando treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(
    X,
    labels,
    test_size=0.25,
    random_state=42,
    stratify=labels
)
mostrar_uso_memoria()


# ===============================
# ETAPA 7 ‚Äî TREINAMENTO
# ===============================
from sklearn.naive_bayes import MultinomialNB

print("[ETAPA 7] Treinando Multinomial Naive Bayes...")
modelo_nb = MultinomialNB()
modelo_nb.fit(X_train, y_train)


# ===============================
# ETAPA 8 ‚Äî AVALIA√á√ÉO
# ===============================
from sklearn.metrics import classification_report

print("\n[RESULTADO] Relat√≥rio de Classifica√ß√£o:")

print(classification_report(
    y_test,
    modelo_nb.predict(X_test),
    labels=labels_ordem,
    target_names=nomes_classes,
    zero_division=0
))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

print("[ETAPA 9] Matriz de confus√£o...")

cm = confusion_matrix(
    y_test,
    modelo_nb.predict(X_test),
    labels=labels_ordem
)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

disp.plot(
    cmap="Blues",
    xticks_rotation=45
)

plt.title("Matriz de Confus√£o ‚Äî MultinomialNB")
plt.tight_layout()
plt.show()

mostrar_uso_memoria()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from itertools import cycle
import matplotlib.pyplot as plt

print("[ETAPA 10] Curvas ROC Multiclasse...")

# Binariza√ß√£o expl√≠cita
y_test_bin = label_binarize(y_test, classes=labels_ordem)
y_prob = modelo_nb.predict_proba(X_test)

plt.figure(figsize=(8, 6))
colors = cycle(plt.cm.tab10.colors)

for i, color in zip(range(len(labels_ordem)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)

    plt.plot(
        fpr,
        tpr,
        lw=2,
        color=color,
        label=f"Classe {labels_ordem[i]} (AUC={roc_auc:.2f})"
    )

plt.plot([0, 1], [0, 1], "k--", lw=1)
plt.xlabel("Taxa de Falsos Positivos")
plt.ylabel("Taxa de Verdadeiros Positivos")
plt.title("Curvas ROC ‚Äî MultinomialNB (Multiclasse)")
plt.legend(fontsize=8)
plt.grid(True)
plt.tight_layout()
plt.show()