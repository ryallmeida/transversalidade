# -*- coding: utf-8 -*-
"""linear_svc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lDkn-t1gvodMq67KOzTQJp-7llUI_LGv

ALGORITMO USADO PARA PROCESSAR A CORPORA DO PROJETO INTITULADO: EVIDENCIAS DO USO DE ALGORITMOS DE PROCESSAMENTO DE LINGUAGEM NATURAL E MACHINE LEARNING APLICADOS COMO FERRAMENTA DIAGOSTICA à TRANSVERSALIDADE EM PERNAMBUCO

CODADO ORIGINALMENTE EM PYTHON VIA GOOGLE COLAB, POR RYAN ALMEIDA. UNIVERSIDADE FEDERAL DE PERNAMBUCO, DEPARTAMENTO DE CIÊNCIA POLÍTICA. PARA ANNALS OF DATA ANALYSIS. 2025-2026. EM CASO DE ERROS ENTRE EM CONTATO COM AUTOR.

## **CLASSE TIPO 1 BALANCEADA**
"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_balanceado_tp1.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf,
                                                    labels_svm,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc,
                                        method='sigmoid',
                                        cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)


# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 1')
plt.legend(loc='lower right')
plt.grid(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Gera as previsões do modelo treinado
y_pred = clf_svc.predict(X_test)

# Gera a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=np.unique(labels_svm))

# Plota a matriz de confusão
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Matriz de Confusão - OneVsRest com LinearSVC Calibrado")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""## **CLASSE DO TIPO 2 BALANCEADA**"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_balanceado_tp2.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['espectro_tipo2'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

print(classification_report(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem,
    target_names=nomes_classes
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

y_bin = label_binarize(labels_svm, classes=labels_ordem)
n_classes = y_bin.shape[1]

X_train, X_test, y_train, y_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.2,
    random_state=42,
    stratify=labels_svm
)

y_test_bin = label_binarize(y_test, classes=labels_ordem)

base_svc = LinearSVC(
    max_iter=10000,
    class_weight="balanced"
)

calibrated_svc = CalibratedClassifierCV(
    estimator=base_svc,
    method='sigmoid',
    cv=3
)

clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

y_score = clf_svc.predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(plt.cm.tab10.colors)

plt.figure(figsize=(9, 7))

for i, color in zip(range(n_classes), colors):
    plt.plot(
        fpr[i],
        tpr[i],
        color=color,
        lw=2,
        label=f'Classe {labels_ordem[i]} (AUC = {roc_auc[i]:0.2f})'
    )

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 2')
plt.legend(loc='lower right', fontsize=9)
plt.grid(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Ordem explícita das classes (MESMA do classification_report)
labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

# Gera as previsões do modelo treinado
y_svm_pred = clf_svm.predict(X_svm_test)

# Gera a matriz de confusão com ordem controlada
cm = confusion_matrix(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem
)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

# Plota a matriz de confusão
plt.figure(figsize=(8, 7))
disp.plot(
    cmap=plt.cm.Blues,
    values_format='d',
    xticks_rotation=45
)

plt.title("TIPO 2")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""## **CLASSE DO TIPO 3 BALANCEADA**"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_balanceado_tp3.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['espectro_tipo3'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

labels_ordem = [-6,-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-6",
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

print(classification_report(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem,
    target_names=nomes_classes
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

labels_ordem = [-6, -5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

y_bin = label_binarize(labels_svm, classes=labels_ordem)
n_classes = y_bin.shape[1]

X_train, X_test, y_train, y_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.2,
    random_state=42,
    stratify=labels_svm
)

y_test_bin = label_binarize(y_test, classes=labels_ordem)

base_svc = LinearSVC(
    max_iter=10000,
    class_weight="balanced"
)

calibrated_svc = CalibratedClassifierCV(
    estimator=base_svc,
    method='sigmoid',
    cv=3
)

clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

y_score = clf_svc.predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(plt.cm.tab10.colors)

plt.figure(figsize=(9, 7))

for i, color in zip(range(n_classes), colors):
    plt.plot(
        fpr[i],
        tpr[i],
        color=color,
        lw=2,
        label=f'Classe {labels_ordem[i]} (AUC = {roc_auc[i]:0.2f})'
    )

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 3')
plt.legend(loc='lower right', fontsize=9)
plt.grid(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Ordem explícita das classes (MESMA do classification_report)
labels_ordem = [-6, -5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-6",
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

# Gera as previsões do modelo treinado
y_svm_pred = clf_svm.predict(X_svm_test)

# Gera a matriz de confusão com ordem controlada
cm = confusion_matrix(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem
)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

# Plota a matriz de confusão
plt.figure(figsize=(8, 7))
disp.plot(
    cmap=plt.cm.Blues,
    values_format='d',
    xticks_rotation=45
)

plt.title("TIPO 3")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""## **MANIPULAÇÃO DO CORPUS DESBALANCEADO**

# **TIPO 1**
"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_desbalanceado.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf,
                                                    labels_svm,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc,
                                        method='sigmoid',
                                        cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)


# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 1')
plt.legend(loc='lower right')
plt.grid(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Gera as previsões do modelo treinado
y_pred = clf_svc.predict(X_test)

# Gera a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=np.unique(labels_svm))

# Plota a matriz de confusão
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Matriz de Confusão - OneVsRest com LinearSVC Calibrado")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# **TIPO 2**"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_desbalanceado.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['espectro_tipo2'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

print(classification_report(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem,
    target_names=nomes_classes
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

y_bin = label_binarize(labels_svm, classes=labels_ordem)
n_classes = y_bin.shape[1]

X_train, X_test, y_train, y_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.2,
    random_state=42,
    stratify=labels_svm
)

y_test_bin = label_binarize(y_test, classes=labels_ordem)

base_svc = LinearSVC(
    max_iter=10000,
    class_weight="balanced"
)

calibrated_svc = CalibratedClassifierCV(
    estimator=base_svc,
    method='sigmoid',
    cv=3
)

clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

y_score = clf_svc.predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(plt.cm.tab10.colors)

plt.figure(figsize=(9, 7))

for i, color in zip(range(n_classes), colors):
    plt.plot(
        fpr[i],
        tpr[i],
        color=color,
        lw=2,
        label=f'Classe {labels_ordem[i]} (AUC = {roc_auc[i]:0.2f})'
    )

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 2')
plt.legend(loc='lower right', fontsize=9)
plt.grid(False)
plt.tight_layout()
plt.show()



from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Ordem explícita das classes (MESMA do classification_report)
labels_ordem = [-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

# Gera as previsões do modelo treinado
y_svm_pred = clf_svm.predict(X_svm_test)

# Gera a matriz de confusão com ordem controlada
cm = confusion_matrix(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem
)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

# Plota a matriz de confusão
plt.figure(figsize=(8, 7))
disp.plot(
    cmap=plt.cm.Blues,
    values_format='d',
    xticks_rotation=45
)

plt.title("TIPO 2")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# TIPO 3"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_desbalanceado.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['texto_limpo'].values)
labels_svm = df_corpus_svm_sem_na['espectro_tipo3'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

labels_ordem = [-6,-5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-6",
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

print(classification_report(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem,
    target_names=nomes_classes
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

labels_ordem = [-6, -5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

y_bin = label_binarize(labels_svm, classes=labels_ordem)
n_classes = y_bin.shape[1]

X_train, X_test, y_train, y_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.2,
    random_state=42,
    stratify=labels_svm
)

y_test_bin = label_binarize(y_test, classes=labels_ordem)

base_svc = LinearSVC(
    max_iter=10000,
    class_weight="balanced"
)

calibrated_svc = CalibratedClassifierCV(
    estimator=base_svc,
    method='sigmoid',
    cv=3
)

clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

y_score = clf_svc.predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(plt.cm.tab10.colors)

plt.figure(figsize=(9, 7))

for i, color in zip(range(n_classes), colors):
    plt.plot(
        fpr[i],
        tpr[i],
        color=color,
        lw=2,
        label=f'Classe {labels_ordem[i]} (AUC = {roc_auc[i]:0.2f})'
    )

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('TIPO 3')
plt.legend(loc='lower right', fontsize=9)
plt.grid(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Ordem explícita das classes (MESMA do classification_report)
labels_ordem = [-6, -5, -4, -3, -2, 0, 2, 3, 4, 5, 6]

nomes_classes = [
    "-6",
    "-5",
    "-4",
    "-3",
    "-2",
    "0",
    "2",
    "3",
    "4",
    "5",
    "6"
]

# Gera as previsões do modelo treinado
y_svm_pred = clf_svm.predict(X_svm_test)

# Gera a matriz de confusão com ordem controlada
cm = confusion_matrix(
    y_svm_test,
    y_svm_pred,
    labels=labels_ordem
)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=nomes_classes
)

# Plota a matriz de confusão
plt.figure(figsize=(8, 7))
disp.plot(
    cmap=plt.cm.Blues,
    values_format='d',
    xticks_rotation=45
)

plt.title("TIPO 3")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()