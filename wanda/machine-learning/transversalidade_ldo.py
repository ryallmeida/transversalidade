# -*- coding: utf-8 -*-
"""transversalidade_ldo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qb9XdnJGMF-6r5MREGZi0x2Jkp4hAkkp
"""

import pandas as pd
import numpy as np

# Leitura do corpus e limpeza
df_corpus_linear_svc = pd.read_csv("/content/corpus_preprocessado_ldo.csv")
df_corpus_svm_sem_na = df_corpus_linear_svc.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['Texto'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf,
                                                    labels_svm,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc,
                                        method='sigmoid',
                                        cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC - One-vs-Rest com LinearSVC (Calibrado)')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Gera as previsões do modelo treinado
y_pred = clf_svc.predict(X_test)

# Gera a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Cria o display da matriz de confusão
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=np.unique(labels_svm))

# Plota a matriz de confusão
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Matriz de Confusão - OneVsRest com LinearSVC Calibrado")
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.grid(False)
plt.tight_layout()
plt.show()

"""## CODIGO CALIBRADO: NAIVE BAYES"""

import pandas as pd
import numpy as np
import psutil
import os
import time

# --- Função auxiliar para mostrar uso de memória ---
def mostrar_uso_memoria():
    processo = psutil.Process(os.getpid())
    mem = processo.memory_info().rss / (1024 ** 2)  # em MB
    print(f"[INFO] Uso atual de memória RAM: {mem:.2f} MB")

print("[ETAPA 1] Lendo o corpus...")
df_corpus = pd.read_csv("/content/corpus_preprocessado_ldo.csv")
mostrar_uso_memoria()

# Verifica colunas
print("[INFO] Colunas do corpus:", df_corpus.columns.tolist())

print("[ETAPA 2] Removendo entradas com dados faltantes...")
df_corpus = df_corpus.dropna(subset=["Texto", "label_final"])
mostrar_uso_memoria()

# Separação de variáveis
textos = df_corpus["Texto"].values
labels = df_corpus["label_final"].values
print(f"[INFO] Total de amostras após limpeza: {len(textos)}")

# Vetorização com CountVectorizer
print("[ETAPA 3] Vetorizando os textos com CountVectorizer...")
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(textos)
mostrar_uso_memoria()

# Cálculo da esparsidade
total_elementos = X.shape[0] * X.shape[1]
elementos_nao_zero = X.nnz
esparcidade = 1.0 - (elementos_nao_zero / total_elementos)
print(f"[INFO] Esparsidade da matriz: {esparcidade:.4f} (valores próximos de 1 indicam muitos zeros)")

# Divisão treino/teste
from sklearn.model_selection import train_test_split
print("[ETAPA 4] Separando dados de treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42, stratify=labels)
mostrar_uso_memoria()

# Treinamento do modelo
from sklearn.naive_bayes import MultinomialNB
print("[ETAPA 5] Treinando o classificador Multinomial Naive Bayes...")
modelo_nb = MultinomialNB()
modelo_nb.fit(X_train, y_train)

# Avaliação
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
print("[ETAPA 6] Avaliando o modelo...")
y_pred = modelo_nb.predict(X_test)
print("\n[RESULTADO] Relatório de Classificação:")
print(classification_report(y_test, y_pred, target_names=["Positive", "Neutral", "Negative"]))

# Matriz de Confusão
print("[ETAPA 7] Gerando matriz de confusão...")
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Positive", "Neutral", "Negative"])
disp.plot(cmap="Blues")
mostrar_uso_memoria()

# Curvas ROC
print("[ETAPA 8] Calculando curva ROC...")
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle

# Binariza as classes
classes_unicas = np.unique(labels)
y_test_bin = label_binarize(y_test, classes=classes_unicas)
y_prob = modelo_nb.predict_proba(X_test)

plt.figure(figsize=(8, 6))
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])

for i, color in zip(range(len(classes_unicas)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2, label=f'Classe {classes_unicas[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.title('Curva ROC - MultinomialNB com CountVectorizer')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()





"""## PROCESSAMENTO [LDO]"""

import pandas as pd
import numpy as np

df_corpus_ldo = pd.read_csv("/content/dic2_corpus_ldo.csv")

print(df_corpus_ldo)

# ELIMINANDO NaN DO CORPUS
df_corpus_sem_na = df_corpus_ldo.dropna()

# LISTA DE LABELS SEM NaNs
label_final = list(df_corpus_sem_na['label_final'].values)
label_final

# LISTA DE TEXTOS SEM NAs
textos = list(df_corpus_sem_na['paragrafo'].values)
print(textos)

#limpeza de textos
#lematização (despersonaliza o sujeito)
#stop words (palavras como "sua", "uma", "o", "a"....)
def preprocessamento(textos):
  #tratando qq um que não seja string
  textos = list(map(str,textos))
  #criação de objeto para cada texto
  docs = list(nlp.pipe(textos))
  #aplicando tokenização, remoção de stop words e part-of-speech tagging
  textos_preprocessados = []
  for doc in docs:
    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
    textos_preprocessados.append(' '.join(tokens))
#retorna os resultados do preprocessamento
  return np.array(textos_preprocessados)

import spacy #carregando bibliotecas e funções de limpeza dos textos
get_ipython().system('python -m spacy download pt_core_news_lg')
nlp = spacy.load("pt_core_news_lg")
texto_corpus_preprocessados = preprocessamento(textos)

print(texto_corpus_preprocessados)

df_corpus_preprocessado = pd.DataFrame(list(zip(texto_corpus_preprocessados,df_corpus_sem_na['label_final'])),
                                        columns = ['Texto','label_final'])

df_corpus_preprocessado.to_csv(r"/content/corpus_preprocessado_ldo.csv")

"""## LINEAR SVC

As Máquinas de Vetores de Suporte (SVM) têm algumas desvantagens importantes. Quando existem muitos detalhes sobre os dados (muitas variáveis) e poucos exemplos para treinar a máquina, ela pode acabar decorando esses exemplos em vez de aprender de forma geral — o que causa erros quando aparecem novos casos.

Por isso, é fundamental escolher bem quais detalhes usar (funções kernel) e ajustar um parâmetro que evita esse excesso de adaptação (o termo de regularização). Outro problema é que o SVM não informa diretamente a confiança nas respostas; ele apenas classifica, sem dizer o quanto está certo.

Para estimar essa confiança, é preciso usar um processo mais lento e trabalhoso chamado **validação cruzada**. Além disso, o SVM só funciona bem se os dados forem entregues em um formato específico, como arquivos bem organizados, sejam eles densos (com todas as informações preenchidas) ou esparsos (mais compactos).

Mas atenção: se a máquina for treinada com um tipo de dado, ela só funcionará corretamente com esse mesmo tipo depois. Para obter o melhor desempenho, é indicado usar dados bem organizados e com números de alta precisão.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

"""Este trecho de código Python é um exemplo clássico de pipeline de aprendizado de máquina utilizando a biblioteca **Scikit-learn**, com o objetivo de construir, treinar e avaliar um modelo de classificação do tipo **Máquina de Vetores de Suporte Linear (LinearSVC)**. A seguir, explico passo a passo o que cada parte faz, em linguagem simples e encadeada.

Primeiramente, o código importa as bibliotecas necessárias. A `pandas` é usada para manipulação de dados, enquanto `train_test_split` serve para dividir o conjunto de dados em uma parte para treino e outra para teste, de forma a avaliar o desempenho do modelo. Em seguida, `make_pipeline` permite montar uma sequência (pipeline) de etapas que serão aplicadas automaticamente ao longo do processo de treinamento e predição. O `StandardScaler` é um transformador que padroniza os dados — ou seja, transforma os valores das variáveis para que tenham média zero e desvio padrão um —, o que é importante para que o modelo de SVM funcione corretamente.

O `LinearSVC` é o modelo de classificação utilizado. Ele é uma versão eficiente da Máquina de Vetores de Suporte (SVM) para problemas com muitos dados, e busca encontrar uma linha (ou plano) que separe as classes com a maior margem possível. Depois, são importadas funções para avaliar o modelo, como `accuracy_score` (que calcula a porcentagem de acertos), `confusion_matrix` (que mostra como o modelo errou ou acertou para cada classe) e `classification_report` (que resume métricas como precisão, recall e F1-score). Por fim, `matplotlib.pyplot` e `seaborn` são bibliotecas gráficas que permitem visualizar os resultados de maneira mais clara e intuitiva, especialmente por meio de gráficos e mapas de calor.

Portanto, este código estabelece a base para: importar e preparar os dados, normalizá-los automaticamente, treinar um modelo de classificação com SVM linear e avaliar seu desempenho por meio de métricas e gráficos. É uma estrutura bastante comum em projetos de machine learning supervisionado.

"""

# Carregando o dataset
df_corpus_linear_svc = pd.read_csv("/content/corpus_preprocessado_ldo.csv")

# Separando X (preditores) e y (alvo)

X = df_corpus_linear_svc.drop(columns=['label_final'])
y = df_corpus_linear_svc['label_final']

print(X)
print(y)

# 4. Dividindo em treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42)

# 5. Criando o pipeline com padronização + SVM linear
clf = make_pipeline(
    StandardScaler(),
    LinearSVC(random_state=42, dual=False, C=1.0, max_iter=10000)
)

# Leitura do corpus e limpeza
df_corpus_svm = pd.read_csv("/content/corpus_preprocessado_ldo.csv")
df_corpus_svm_sem_na = df_corpus_svm.dropna()

# Extração de textos e rótulos
textos_svm = list(df_corpus_svm_sem_na['Texto'].values)
labels_svm = df_corpus_svm_sem_na['label_final'].values

# Vetorização com TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer_svm = TfidfVectorizer()
X_svm_tfidf = tfidf_vectorizer_svm.fit_transform(textos_svm)

# Separação dos dados em treino e teste
from sklearn.model_selection import train_test_split
X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(
    X_svm_tfidf,
    labels_svm,
    test_size=0.25,
    random_state=0
)

# Treinamento do modelo SVM
from sklearn.svm import LinearSVC
clf_svm = LinearSVC()
clf_svm.fit(X_svm_train, y_svm_train)

# Predição e avaliação
from sklearn.metrics import classification_report
y_svm_pred = clf_svm.predict(X_svm_test)

print(classification_report(
    y_svm_test,
    y_svm_pred,
    target_names=["Positive", "Neutral", "Negative"]
))

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline

import numpy as np

# Binarizar os rótulos
y_svm_binarized = label_binarize(y_svm_test, classes=[0, 1, 2])  # ou use as labels reais se forem strings

# Treinar modelo com probabilidade habilitada
# OBS: LinearSVC não suporta predict_proba, então usamos SVC
clf_roc = OneVsRestClassifier(SVC(kernel="linear", probability=True))
clf_roc.fit(X_svm_train, y_svm_train)
y_score = clf_roc.predict_proba(X_svm_test)

# Número de classes
n_classes = y_score.shape[1]

# Plot da curva ROC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_svm_binarized[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot
plt.figure(figsize=(8, 6))
colors = ['blue', 'green', 'red']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC Multiclasse (One-vs-Rest)')
plt.legend(loc="lower right")
plt.grid()
plt.show()

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# Binariza as labels para avaliação multiclasse
y_bin = label_binarize(labels_svm, classes=np.unique(labels_svm))
n_classes = y_bin.shape[1]

# Usa stratify para manter proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X_svm_tfidf, labels_svm, test_size=0.2, random_state=42, stratify=labels_svm)

# Binariza o y_test (usado na avaliação ROC)
y_test_bin = label_binarize(y_test, classes=np.unique(labels_svm))

# Cria um modelo LinearSVC calibrado (com o nome do parâmetro correto para versões < 1.1)
base_svc = LinearSVC(max_iter=10000)
calibrated_svc = CalibratedClassifierCV(estimator=base_svc, method='sigmoid', cv=3)

# One-vs-Rest com SVC calibrado
clf_svc = OneVsRestClassifier(calibrated_svc)
clf_svc.fit(X_train, y_train)

# Previsões em forma de probabilidade
y_score = clf_svc.predict_proba(X_test)

# Calcula curva ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Gráfico ROC
colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
plt.figure(figsize=(8, 6))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Classe {np.unique(labels_svm)[i]} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC - One-vs-Rest com LinearSVC (Calibrado)')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Leitura do corpus
df = pd.read_csv("/content/corpus_preprocessado_ldo.csv")
df = df.dropna()

# Verificando distribuição das classes
print("\nDistribuição de classes:")
print(df['label_final'].value_counts(normalize=True))
print("\nTotal por classe:", df['label_final'].value_counts())

# Verificando se há apenas três classes
print("\nClasses únicas encontradas:", df['label_final'].unique())

# Extração dos textos e rótulos
textos = df['Texto'].values
labels = df['label_final'].values

# Vetorização com TF-IDF
tfidf = TfidfVectorizer()
X = tfidf.fit_transform(textos)

# Separação treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=0, stratify=labels)

# Treinamento do modelo
clf = LinearSVC(class_weight="balanced", random_state=0)
clf.fit(X_train, y_train)

# Predições
y_pred = clf.predict(X_test)

# Avaliação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

# Matriz de confusão visual
cm = confusion_matrix(y_test, y_pred, labels=np.unique(labels))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=np.unique(labels), yticklabels=np.unique(labels))
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title("Matriz de Confusão")
plt.show()

# Verificando termos mais importantes por classe
try:
    coef = clf.coef_
    for i, classe in enumerate(clf.classes_):
        print(f"\nTop termos para a classe {classe}:")
        top_n = np.argsort(coef[i])[-10:]  # top 10 positivos
        termos = np.array(tfidf.get_feature_names_out())[top_n]
        print(termos)
except Exception as e:
    print("\nErro ao tentar extrair os coeficientes dos termos:", str(e))

"""A avaliação do modelo de classificação textual com o algoritmo Linear Support Vector Classifier (LinearSVC), treinado a partir da vetorização TF-IDF dos documentos do corpus, revelou resultados bastante satisfatórios. Utilizando uma divisão estratificada entre treino e teste (75% e 25%, respectivamente), o modelo alcançou uma acurácia global de 94%, com f1-score médio ponderado de 0,94. Esses resultados indicam um desempenho robusto, mesmo diante da assimetria na distribuição de classes observada na análise exploratória inicial.

A matriz de confusão e o relatório de classificação apontam que a classe majoritária, rotulada como "0" (interpretação neutra), foi corretamente identificada na maioria dos casos, com um recall de 0,94 e precisão de 0,96. As classes minoritárias – "1" (positiva) e "-1" (negativa) – também apresentaram desempenho expressivo, com f1-scores de 0,92 e 0,87, respectivamente. Esses resultados demonstram que, apesar do desbalanceamento natural do corpus (com 66,9% de textos neutros, 23,1% positivos e apenas 9,8% negativos), o modelo foi capaz de aprender a distinguir os padrões linguísticos mais relevantes para cada polaridade de texto.

No entanto, a análise mais detalhada da matriz de confusão evidencia algumas limitações importantes. Observou-se que a maior parte dos erros de classificação está concentrada entre a classe neutra e as classes positivas ou negativas, ou seja, textos originalmente classificados como neutros foram, em alguns casos, confundidos com positivos ou negativos. Isso sugere que há uma sobreposição semântica considerável entre essas categorias, possivelmente em decorrência da natureza ambígua de parte dos enunciados ou da dificuldade intrínseca em distinguir tons sutis de positividade ou negatividade em textos institucionais.

Outro ponto de atenção está relacionado à classe negativa (-1), que, apesar do bom desempenho geral, foi parcialmente confundida com a classe neutra. A ausência de confusões entre as classes extremas (positivo vs. negativo) é, por outro lado, um indicativo de que o modelo está capturando corretamente os contrastes mais evidentes no conteúdo textual.

Em síntese, o modelo demonstrou ser funcional e bem ajustado ao problema, apresentando desempenho elevado mesmo em um cenário de desbalanceamento. Para aprimoramentos futuros, recomenda-se o uso de técnicas de balanceamento como aumento sintético da classe minoritária (por exemplo, via SMOTE ou data augmentation textual), bem como a reavaliação dos critérios de anotação da classe neutra, que aparenta capturar uma faixa semântica muito ampla. Tais medidas podem contribuir para aumentar a acurácia nos limites mais difusos entre as classes e ampliar a generalização do modelo.

## NAIVE BAYES
"""

df_corpus = pd.read_csv("/content/corpus_preprocessado_ldo.csv")
print(df_corpus)
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

#eliminando NaN do corpus
df_corpus_sem_na = df_corpus.dropna()


#lista de textos sem NaNs
textos = list(df_corpus_sem_na['Texto'].values)

#eliminando NaN do corpus
df_corpus_sem_na = df_corpus.dropna()


#lista de textos sem NaNs
textos = list(df_corpus_sem_na['Texto'].values)
textos

count_vectorizer = CountVectorizer()
tfidf_vectorizer = TfidfVectorizer()

X_cv = count_vectorizer.fit_transform(textos)
X_tv = tfidf_vectorizer.fit_transform(textos)

#Imprimindo a matriz obtida com o CountVectorizer
#X_cv.toarray()

total_elementos_cv = X_cv.shape[0]*X_cv.shape[1]
elementos_nao_zero_cv = X_cv.nnz
esparcidade_cv = 1.0 - (elementos_nao_zero_cv/total_elementos_cv)
# formula especifica para a esparcidade
esparcidade_cv


#identificando esparcidade (raridade na presença de certas palavras = 0)
# valor proximo de 1 indica que a matriz é quase toda de zeros

print(X_cv.toarray())

total_elementos_tv = X_tv.shape[0]*X_tv.shape[1]
elementos_nao_zero_tv = X_tv.nnz
esparcidade_tv = 1.0 - (elementos_nao_zero_tv/total_elementos_tv)
esparcidade_tv
#criando lista contando etiquetas associadas aos textos:
labels = df_corpus_sem_na['label_final'].values
labels



#Naive bayes
#Classificação de features discretas - trata-se um classificador probabilísticos
#O algoritmo estima a probabilidade condicional de uma classe particular dado um vetor de características.
#Distribuição multinomial
#separando os conjuntos de treinamento e teste

from sklearn.model_selection import train_test_split

X_cv_train, X_cv_test, y_train, y_test = train_test_split(X_cv,
                                                       labels,     #y
                                                       test_size = 0.25,#deixando reservado 15% dos dados para realizar teste
                                                       random_state = 0)

X_tv_train, X_tv_test, y_train, y_test = train_test_split(X_tv,
                                                       labels,#y
                                                       test_size = 0.25,#deixando reservado 15% dos dados para realizar teste
                                                       random_state = 0)

#treinando o modelo
from sklearn.naive_bayes import MultinomialNB

mnb = MultinomialNB()

from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
!pip install scikit-plot
!pip install skplt

from sklearn import model_selection
#criar o classificador propriamente dito e realizar a classificação
print(X_cv_test)
X_cv_train

clf_cv = mnb.fit(X_cv_train,y_train)
predict_cv = clf_cv.predict(X_cv_test)

print(classification_report(y_test,
                              predict_cv,
                              target_names=["Positive","Neutral","Negative"]))#gerando relatório de classificação - ACURÁCIA ACIMA DE 70% É O IDEAL

# Passo 4: Plotar a matriz de confusão
from sklearn.metrics import confusion_matrix # import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
# Calculate the confusion matrix from the predictions and true labels
cm = confusion_matrix(y_test, predict_cv)

target_names=["Positivo","Neutro","Negativo"]
def plot_confusion_matrix(cm, classes, title='Matriz de Confusão', cmap=plt.cm.Blues):
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.xlabel('Predito')
    plt.ylabel('Real')
    plt.show()

# Exibir o gráfico
plot_confusion_matrix(cm, classes=target_names, title='Matriz de Confusão Naive Bayes com CV')

labels_prob_cv = clf_cv.predict_proba(X_cv_test)
print(labels_prob_cv)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

def plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC", figsize=(8,6)):
    """
    Plota a Curva ROC para múltiplas classes.

    Parâmetros:
    - y_test: Array com os rótulos verdadeiros.
    - labels_prob_cv: Array com as probabilidades previstas para cada classe.
    - title: Título do gráfico.
    - figsize: Tamanho da figura.
    """
    plt.figure(figsize=figsize)

    # Obter o número de classes
    num_classes = labels_prob_cv.shape[1]

    for i in range(num_classes):
        # Calcular a curva ROC
        fpr, tpr, _ = roc_curve(y_test, labels_prob_cv[:, i], pos_label=i)
        roc_auc = auc(fpr, tpr)

        # Plotar a curva ROC
        plt.plot(fpr, tpr, lw=2, label=f'Classe {i} (AUC = {roc_auc:.2f})')

    # Adicionar a linha diagonal (linha de aleatoriedade)
    plt.plot([0, 1], [0, 1], 'k--', lw=2)

    # Adicionar título e rótulos
    plt.title(title)
    plt.xlabel('Taxa de Falsos Positivos')
    plt.ylabel('Taxa de Verdadeiros Positivos')
    plt.legend(loc='lower right')
    plt.grid(True)

    # Mostrar o gráfico
# Plotar as curvas ROC
plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC Naive Bayes com CV", figsize=(8,6))

labels_prob_cv = clf_cv.predict_proba(X_cv_test)
labels_prob_cv

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

def plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC", figsize=(8,6)):
    """
    Plota a Curva ROC para múltiplas classes.

    Parâmetros:
    - y_test: Array com os rótulos verdadeiros.
    - labels_prob_cv: Array com as probabilidades previstas para cada classe.
    - title: Título do gráfico.
    - figsize: Tamanho da figura.
    """
    plt.figure(figsize=figsize)

    # Obter o número de classes
    num_classes = labels_prob_cv.shape[1]

    # Binarize y_test for ROC curve calculation
    from sklearn.preprocessing import label_binarize
    y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))

    for i in range(num_classes):
        # Calculate the ROC curve
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], labels_prob_cv[:, i])
        roc_auc = auc(fpr, tpr)

        # Plot the ROC curve
        plt.plot(fpr, tpr, lw=2, label=f'Classe {np.unique(y_test)[i]} (AUC = {roc_auc:.2f})')

    # Add the diagonal line (randomness line)
    plt.plot([0, 1], [0, 1], 'k--', lw=2)

    # Add title and labels
    plt.title(title)
    plt.xlabel('Taxa de Falsos Positivos')
    plt.ylabel('Taxa de Verdadeiros Positivos')
    plt.legend(loc='lower right')
    plt.grid(True)

    # Show the plot
    plt.show()

# Calculate predicted probabilities
labels_prob_cv = clf_cv.predict_proba(X_cv_test)

# Plot the ROC curves
plot_roc_curves(y_test, labels_prob_cv, title="Curva ROC Naive Bayes com CV", figsize=(8,6))